# 왜 브라우저에선 이모지가 여러 글자로 인식될까?

브라우저에서 문자열 길이를 계산할 때, 우리는 눈에 보이는 '글자 수'가 출력될 것이라 생각한다. 하지만 컴퓨터는 글자를 그림이 아닌 숫자의 조합으로 처리한다. 이 차이 때문에, 우리가 '한 글자'라고 생각하는 이모지가 컴퓨터 입장에서는 여러 글자로 인식된다.

이번 글에서는 자바스크립트에서 이모지가 여러 글자로 인식되는 원인에 대해서 분석하고, 이를 해결하는 방법을 살펴본다.

## 문제 발생

서비스의 QA를 진행하는 도중, 팀원 중 한 명이 input에 이모지를 입력할 시에 길이가 2개 내지는 3개까지 인식되는 것을 발견했다.

> 이모지는 왜 한 글자가 아닌 여러 글자로 인식될까?
> 
> 이를 해결하기 위해 어떤 방식을 도입해 볼 수 있을까?  

이 현상의 원인은 문자열이 **브라우저에서 내부적으로 처리되는 단위**인 **코드 유닛(code unit)** 에 있다.

문제를 해결하기 전에, "왜" 이모지가 여러 글자로 처리되는지 먼저 알아보자.

<br />

## 1. 컴퓨터에서 문자가 처리되는 방식

컴퓨터는 글자를 그 자체로는 인식하지 못한다.

따라서, 글자를 입력했다면 이를 컴퓨터가 인식할 수 있는 0과 1로 번역하는 과정이 필요하다.

이 변환 과정을 "문자 인코딩" 이라고 한다.

<br />

컴퓨터는 문자를 코드 포인트로 먼저 변환하고, 그 이후에 코드 유닛으로 변환한다.

그리고 브라우저는 **이 "코드 유닛"의 개수를 해당 글자의 개수로 인식한다.**

결국 브라우저에서 이모지가 여러 글자로 인식되는 이유를 알기 위해선, 컴퓨터의 문자 인코딩 방식을 이해해야 한다.

<br />

### 1단계 : 코드포인트 매핑

우선, 각 문자는 **16진수로 표현된 숫자**를 하나씩 부여받는다.

이 때, 문자 별로 숫자가 겹치지 않아야 하기 때문에 "유니코드"라는 규칙을 기반으로 매핑된다.

아래는 "가", "A"에게 매핑된 코드포인트이다. 각 문자 별로0x0041, 0xAC00 16진수 숫자가 매핑된 걸 확인할 수 있다.

| **문자** | **코드포인트** |
| --- | --- |
| A | 0x0041 |
| 가 | 0xAC00 |
| … | … |

<br />

### 2단계 : 코드 유닛 인코딩

문자 별로 매핑된 코드포인트는 다시 0과 1의 바이트 배열로 변환된다. 

앞서 말했듯, 컴퓨터는 문자를 0과 1의 바이트로 번역해야 이해할 수 있기 때문이다.

이 때, 변환 규칙으로 UTF(Unicode Transformation Format)를 사용한다.

<br />

UTF도 변환 단위에 따라서 여러 종류가 있다 (ex. UTF-8, UTF-16..)

UTF뒤에 붙는 숫자는 변환 단위를 의미한다. 그리고 이 변환 단위 마다 표현할 수 있는 숫자의 범위가 달라진다.

**여기에서, 이모지는 1개의 코드 유닛으로 표현할 수 있는 범위를 넘어선다.**

**이 때문에 여러 개의 코드 유닛으로 표현되어 브라우저 상에서 여러 글자로 인식됨을 추론해볼 수 있다.**

브라우저는 UTF-16을 사용하지만, 우선 이해를 위해 작은 단위인 UTF-8을 통해 예시를 들어보려고 한다.

<br />

**UTF-8로는 어디부터 어디까지 표현할 수 있을까**

UTF-8은 이름 그대로 8비트(1바이트) 를 기본 단위로 변환하는 규칙이다.

1바이트는 8비트이다. 그리고 1비트는 2^1가지의 수를  표현할 수 있다.

이에 따르면 8비트, 즉 1바이트는 10진수 기준으로 0~127(2⁸−1) 사이의 수를 표현할 수 있다는 뜻이다.

<br />

이 범위를 16진수로 환산해보면, 0x00~0x7F가 나온다.

코드 포인트는 문자 별로 부여된 "16진수의 숫자"이다.

즉, 이는 UTF-8이 코드 포인트로 기준으로 **U+0000부터 U+007F**를 표현할 수 있다는 것과 동일하다.

아래 표를 통해 1바이트마다 표현할 수 있는 코드 포인트의 범위가 달라지는 것을 한 눈에 볼 수있다.

<br />

**표1) UTF-8 인코딩 구간별 코드 유닛 구성표**

| **인코딩 에 필요한 바이트 수** |  **표현 가능한 10진수 범위** |  **표현 가능한 16진수 범위**  | **코드 포인트 범위** |
| --- | --- | --- | --- |
| 1바이트 (8bit) | 0 ~ 127 | 0x00 ~ 0x7F | U+0000 ~ U+007F |
| 2바이트 (16bit) | 128 ~ 2,047 | 0x0080 ~ 0x07FF | U+0080 ~ U+07FF |
| 3바이트 (24bit) | 2,048 ~ 65,535 | 0x0800 ~ 0xFFFF | U+0800 ~ U+FFFF |
| 4바이트 (32bit) | 65,536 ~ 1,114,111 | 0x010000 ~ 0x10FFFF | U+10000 ~ U+10FFFF |

앞서 말했듯, 브라우저에서 자바스크립트 문자열을 내부적으로 표현할 때는 UTF-16 이 사용된다.

즉, 16비트를 기준 단위로 하여 인코딩을 한다.

위에 제시된 표를 16비트를 기준으로 계산한 결과는 다음과 같다.

<br />

**표2) UTF-16 인코딩 구간별 코드 유닛 구성표**

인코딩에 필요한 코드 유닛 수  범위 1 코드 포인트 범위

| **인코딩 에 필요한 바이트 수** | **표현 가능한 10진수 범위** | **표현 가능한 16진수 범위** | **코드 포인트 범위** |
| --- | --- | --- | --- |
| 1개 (16bit, 2바이트) | 0 ~ 55,295 | 0x0000 ~ 0xD7FF | U+0000 ~ U+D7FF |
| 사용 불가 (서러게이트 영역, 추후 설명) | — | 0xD800 ~ 0xDFFF | U+D800 ~ U+DFFF |
| 1개 (16bit, 2바이트) | 57,344 ~ 65,535 | 0xE000 ~ 0xFFFF | U+E000 ~ U+FFFF |
| 2개 (32bit, 4바이트) | 65,536 ~ 1,114,111 | 0x010000 ~ 0x10FFFF | U+10000 ~ U+10FFFF |

"가"라는 글자를 통해 인코딩 예시를 들어보려고 한다.

"가"의 코드포인트는 U+AC00로 (10진수 기준 44032)  U+0000 ~ U+D7FF 범위에 있다.

즉, UTF-16 기준 하나의 코드 유닛으로 표현이 가능하다.

하나의 코드 유닛으로 표현이 가능하기에, 브라우저 상에서 글자수를 연산했을 때도 한 글자로 인식된다.

<br />

**표3) "가"의 UTF-16 인코딩 예시표**

| 인코딩 방식 | "가" 의 코드포인트 | 코드 포인트 범위 | 코드 유닛 크기 | 코드 유닛 개수 | 총 바이트 수 |
| --- | --- | --- | --- | --- | --- |
| UTF-16 | 0xAC00 | U+0000 ~ U+D7FF   (표2 참조) | 16bit (2바이트) | 1개 | 2바이트 |

대부분의 글자 (영어, 한글) 등은 UTF-16 방식에서 하나의 코드유닛으로 표현이 가능하다.

16bit 크기의 코드유닛 하나로 표현이 가능한 U+0000~ U+D7FF 사이의 코드 포인트를 가지기 때문이다.

**이는 다시 말하면 우리가 아는 대다수의 글자는 1개의 코드 유닛을 가지기에 브라우저 상에서 길이가 1로 표현된다는 뜻이다.**

<br />

## 2. 이모지의 코드 유닛 개수는?

**이모지는 내부적으로 여러 개의 코드 유닛을 갖고 있다.**

이유는 다음과 같다.


### 이모지는 코드 유닛 개수를 연산해보자

대부분의 이모지는 U+10000 이상의 매우 큰 코드포인트를 부여받는다.

당연하다. 비교적 최근에 정의된 문자이기 때문에 큰 숫자를 부여받을수밖에 없다.

이 때문에, 이모지는 UTF-16에서 1코드유닛으로 표현할 수 있는 범위인 U+0000~U+FFFF를 넘어서는 경우가 많다.

<br />

"😀" 이모티콘을 예시로 들면 다음과 같다

> 💬**\[예시\] 😀**  
> 😀의 코드포인트는 U+1F600, 16bit를 기준으로 구간을 나눴을 때, 다음 구간에 해당한다  
> **U+10000 ~ U+10FFFF  
> **1코드유닛 범위에서 벗어나기 때문에, 하나의 코드유닛으로 표현이 불가능하다

이모지처럼 1코드유닛의 **범위를 넘어서는 문자를 표현하기 위해선 서러게이트 페어**라는 방식을 사용한다.

간단하게 말하면, 16bit의 코드 유닛 2개가 합쳐져 하나의 문자를 이루는 것이다.

### 서러게이터 페어를 통해서 이모지를 표현해보자

UTF-16 기준, U+FFFF까지는 1 코드유닛으로 직접 표현 가능하다.

2 코드유닛 시작점인 U+10000을 빼는 연산을 통해, 표현이 가능한 영역의 이후 영역을 0부터 다시 표현한다.

**0x1F600** (😀의 코드포인트) **\- 0x10000**(2코드 유닛으로 표현하는 시작점) **\= 0xF600** (10진수 62976)

위 연산의 결과값은 U+0000~U+FFFF 사이에 포함된다.

즉, 해당 이모지는 2개의 코드유닛으로 표현이 가능하다.

이 2개의 코드 유닛을 서러게이트 페어로 구성하여 표현한다.

<br />

> **여담 : 사실 서러게이트 페어는 내부적으로 16비트 전체를 사용하진 않는다**  
> 위 얘기만 들었을 때는 16비트 / 16비트 총 32비트 전체를 문자를 표현하는 데 쓸 것 같지만, 사실 그렇지 않다.  
> 실제 문자 데이터는 16비트 중 10비트만을 사용한다.  
> 일반 문자와 다르게 서러게이트 페어로 표기된 문자라는 식별자가 필요하기에 16비트 중 6비트는 "서러게이트 식별자"로 사용한다. 



### 길이가 3 이상인 이모지

앞서 말했듯, 서러게이트 페어로도 표현하기에도 큰 코드포인트를 가져 길이가 3 이상으로 인식되는 이모지도 있다.

이 이모지들은 "조합" 방식을 사용한다.

결론부터 말하면, 여러 코드 유닛을 접착제로 합쳐서 하나의 문자로 표현한 것과 같다.

ZWJ 라는 연결자를 사용하는데, 여러 이모지를 "붙이는" 역할을 한다.

ZWJ는 접착제고, 접착제의 길이가 1이라고 생각하면 된다.

실제 이모지를 통해 예시를 들어보았다.

> **예시1) 🧑‍💻 = 👦 +ZWJ(1) + 💻**  
> **총 2개의 코드 유닛 (서러게이터 페어, 각 10bit씩 사용 중) + 1개의 ZWJ**  
> 브라우저 상에서 인식되는 총 길이 : 2 x 2 + 1 = 5  
> "🧑‍💻".length === 5  
>   
> **예시2) 👨‍👩‍👧‍👦 = 👨 + ZWJ + 👩 + ZWJ + 👧 + ZWJ + 👦  
> 총 4개의 코드유닛 + 3개의 ZWJ**  
> 브라우저 상에서 인식되는 총 길이 : 2 x 4 + 1 x 3 = 11  
> "👨‍👩‍👧‍👦".length === 11

## 정리 : 왜 이모지는 2개 이상으로 인식되는 경우가 많을까?

**브라우저가 인식하는 것은 코드유닛의 개수이다. 즉, 사람 눈에 보이는 글자수가 아니다.**

자바스크립트(브라우저)는 문자열을 UTF-16 코드 유닛 배열로 다룬다.

따라서 .length는 코드 유닛 개수를 반환한다.

결과적으로, 이모지의 길이는 .length === 2 또는 그 이상으로 연산된다.

## 해결책

이모지의 실제 ‘눈에 보이는 글자 수’를 세고 싶다면, 단순히 .length로 계산하는 대신, 그래핌(grapheme) 단위로 길이를 측정해야 한다.

이때 시도할 수 있는 방법은 다음과 같다.

### Intl.Segmenter (브라우저 내장 API)

-   ECMAScript 국제화 API(ECMA-402)에서 제공하는 기능으로, 문자열을 그래프 클러스터(grapheme) 단위로 분리할 수 있다.
-   다만, 구형 브라우저에서는 지원하지 않는다는 단점이 있다.

```
const segmenter = new Intl.Segmenter("ko", { granularity: "grapheme" });
const input = "🧑‍💻👨‍👩‍👧‍👦"
const segments = [...segmenter.segment(input)]; // ["🧑‍💻", "👨‍👩‍👧‍👦"]
console.log(segments.length); // 2
```

"ko"는 언어(locale)를 지정한 것인데, 여기서는 한국어 기준으로 분리 규칙을 적용하라는 의미이다. 다만 grapheme 모드에서는 언어별로 큰 차이는 없다.

1.  segmenter.segment(input) → 문자열을 grapheme 단위 iterable로 반환한다 (ex.\["🧑‍💻", "👨‍👩‍👧‍👦"\])
2.  segments.length를 통해 위에서 반환된 iterable의 길이를 연산하여 눈에 보이는 문자 수와 동일한 값을 반환할 수 있다.

### Grapheme Splitter (외부 라이브러리)

-   구형 브라우저에서도 지원이 가능하다
-   다만, 성능 측면에서 Intl.Segmenter에 비해 느리다는 단점이 있다
-   가장 치명적인 문제로, **Unicode 최신 대응이 불가능하다**. Unicode는 매년 업데이트 되는데, 이에 따라 "문자를 몇 개로 묶어서 하나로 볼것인가" 와 같은 Grapheme splitter 규칙 또한 함께 바뀐다. Grapheme Splitter은 Unicode 13(2020년 이전) 수준까지만 반영되어 있기 때문에, 이후 업데이트 된 Unicode 규칙에 대응하지 못해 예상치 못한 글자수 연산 결과가 나올 수 있다.

Grapheme Splitter을 사용하여 글자수를 계산한 로직은 다음과 같다.

```
import GraphemeSplitter from "grapheme-splitter";

const splitter = new GraphemeSplitter();

const input = "🧑‍💻👨‍👩‍👧‍👦";
const graphemes = splitter.splitGraphemes(input);

console.log(graphemes); // ["🧑‍💻", "👨‍👩‍👧‍👦"]
console.log(graphemes.length); // 2

```

1.  new GraphemeSplitter()로 글자를 grapheme 단위로 쪼개줄 분리자(splitter)를 생성한다
2.  splitGraphemes 메서드에 문자열을 넣으면, 사람 눈에 보이는 문자(grapheme) 단위로 나눈 배열을 반환한다.
3.  배열의 길이를 세면 실제 사용자가 눈으로 인식하는 문자의 개수를 정확히 얻을 수 있다.

### 두 방법에 대한 비교

위에서 언급했듯

1\. Intl.Segmenter은 구형 브라우저(iOS 기준 13 이전)에서 사용할 수 없다

2\. GraphemeSplitter은 구형 브라우저 대응이 가능하지만, 2020년 이후 업데이트 된 Unicode 규칙을 반영하지 못한다

이 2가지 방식의 장단점을 조합하여 불안정성을 최소화하기 위해 다음과 같이 설정했다.

## 그래서 어떻게 해결했는가?

```
import GraphemeSplitter from 'grapheme-splitter';

const segmenter =
  typeof Intl !== 'undefined' && Intl.Segmenter
    ? new Intl.Segmenter('und', { granularity: 'grapheme' })
    : null;

const splitter = new GraphemeSplitter();

export const calculateValidLength = (text: string): number => {
  if (segmenter) {
    // Intl.Segmenter 사용 (권장)
    return Array.from(segmenter.segment(text), (s) => s.segment).length;
  }
  // fallback: GraphemeSplitter 사용
  return splitter.splitGraphemes(text).length;
};
```

Intl.Segmenter을 기본으로 사용하되, 구형 브라우저에 대한 대응을 위해 GraphemeSplitter로 폴백 설정을 해두었다.

이렇게 될 경우, 기본적으로 Intl.Segmenter을 사용하면서 Unicode 규칙을 안정적으로 적용할 수 있다.

만약 구형 브라우저에서 해당 기능을 사용할 수 없을 경우 Grapheme Splitter가 동작하며 조금이라도 더 안정적인 글자수 연산이 동작할 수 있도록 설정한 것이다.

## 5. 결론

이모지가 여러 글자로 인식되는 이유는 자바스크립트가 문자열을 UTF-16 코드 유닛 단위로 처리하기 때문이다. 눈에 보이는 글자 수를 정확히 계산하려면, 문자열을 grapheme 단위로 분리해야 한다. 최신 브라우저에서는 Intl.Segmenter, 그 외 환경에서는 Grapheme Splitter를 사용하면 된다.

문서에서 설명했던 전체 인코딩 과정에 대해서 그림을 통해 정리해보았다.

[##_Image|kage@AMEfJ/btsQ59ZA6SJ/AAAAAAAAAAAAAAAAAAAAAO6GroRTZVvR-oS6_wjYaoJm8NvgZwsU-gzeSj6AnVs2/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1764514799&amp;allow_ip=&amp;allow_referer=&amp;signature=FPdRa6uH8Y7c6ajAeTdjIsJkxWA%3D|CDM|1.3|{"originWidth":1280,"originHeight":1059,"style":"alignCenter","caption":"정리표"}_##]
